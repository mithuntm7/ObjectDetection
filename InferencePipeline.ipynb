{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_pretrained in module transformers.processing_utils:\n",
      "\n",
      "from_pretrained(pretrained_model_name_or_path, **kwargs) method of builtins.type instance\n",
      "    Instantiate a processor associated with a pretrained model.\n",
      "    \n",
      "    <Tip>\n",
      "    \n",
      "    This class method is simply calling the feature extractor\n",
      "    [`~feature_extraction_utils.FeatureExtractionMixin.from_pretrained`] and the tokenizer\n",
      "    [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`] methods. Please refer to the docstrings of the\n",
      "    methods above for more information.\n",
      "    \n",
      "    </Tip>\n",
      "    \n",
      "    Args:\n",
      "        pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
      "            This can be either:\n",
      "    \n",
      "            - a string, the *model id* of a pretrained feature_extractor hosted inside a model repo on\n",
      "              huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or\n",
      "              namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.\n",
      "            - a path to a *directory* containing a feature extractor file saved using the\n",
      "              [`~SequenceFeatureExtractor.save_pretrained`] method, e.g., `./my_model_directory/`.\n",
      "            - a path or url to a saved feature extractor JSON *file*, e.g.,\n",
      "              `./my_model_directory/preprocessor_config.json`.\n",
      "        **kwargs\n",
      "            Additional keyword arguments passed along to both\n",
      "            [`~feature_extraction_utils.FeatureExtractionMixin.from_pretrained`] and\n",
      "            [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help( OwlViTProcessor.from_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(\"/content/gorceryitems.webp\")\n",
    "texts = [[ \"food item\", \"a grocery item\"]]\n",
    "inputs = processor(text=texts, images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n",
    "target_sizes = torch.Tensor([image.size[::-1]])\n",
    "# Convert outputs (bounding boxes and class logits) to COCO API\n",
    "results = processor.post_process(outputs=outputs, target_sizes=target_sizes)\n",
    "\n",
    "i = 0  # Retrieve predictions for the first image for the corresponding text queries\n",
    "text = texts[i]\n",
    "boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
    "\n",
    "score_threshold = 0.1\n",
    "thresholded_boxes = []\n",
    "for box, score, label in zip(boxes, scores, labels):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    if score >= score_threshold:\n",
    "      thresholded_boxes.append(box)\n",
    "      #print(f\"Detected {text[label]} with confidence {round(score.item(), 3)} at location {box}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6680bb41b3b21afd2fcaa2fd2d2f2c634d8159c3435ffc0aa2cb21155ca376d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
